{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Step 1, which is to train a Siamese network to compute the similarity between two poses:\n",
    "\n",
    "you would need a dataset of pairs of poses with corresponding labels indicating whether the pairs are similar or dissimilar. Here's an example of how you can create such a dataset:\n",
    "\n",
    "* Collect a dataset of individual poses: You can use one of the datasets I mentioned earlier, such as NTU RGB+D or Human3.6M, to collect a dataset of individual poses. For example, you can use a pose estimation model to extract 3D joint locations from the RGB or depth frames, and use these joint locations as the features for each pose.\n",
    "\n",
    "* Generate pairs of poses: To create the dataset of pairs of poses, you can randomly select two poses from the dataset and concatenate their feature vectors to create a single input vector for the Siamese network. You can then assign a label of 1 if the two poses are similar (e.g. the same pose from different angles), and a label of 0 if they are dissimilar (e.g. two different poses).\n",
    "\n",
    "* Shuffle and split the dataset: Once you have created the dataset of pairs of poses, you can shuffle the data and split it into training and validation sets. You can use the training set to train the Siamese network, and the validation set to evaluate its performance.\n",
    "\n",
    "Note that the dataset size and complexity will depend on the specific problem you are trying to solve. You may need to adjust the dataset size and complexity to achieve good performance on your specific task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from h36m_dataset import H36MDataset # replace with your own Human3.6M dataset implementation\n",
    "\n",
    "# Create a dataset of individual poses\n",
    "pose_dataset = H36MDataset() # replace with your own Human3.6M dataset implementation\n",
    "poses = pose_dataset.get_poses()\n",
    "\n",
    "# Create pairs of poses and corresponding labels\n",
    "num_pairs = 10000 # number of pairs to generate\n",
    "pos_pairs = []\n",
    "neg_pairs = []\n",
    "pos_labels = []\n",
    "neg_labels = []\n",
    "for i in range(num_pairs):\n",
    "    # Select two random poses from the dataset\n",
    "    pos1, pos2 = np.random.choice(poses, size=2, replace=False)\n",
    "    \n",
    "    # Concatenate the feature vectors to create a pair of inputs for the Siamese network\n",
    "    pos_pair = np.concatenate((pos1, pos2))\n",
    "    \n",
    "    # Assign a label of 1 for similar poses, and 0 for dissimilar poses\n",
    "    if pos1.action == pos2.action and pos1.subject == pos2.subject:\n",
    "        pos_pairs.append(pos_pair)\n",
    "        pos_labels.append(1)\n",
    "    else:\n",
    "        neg_pairs.append(pos_pair)\n",
    "        neg_labels.append(0)\n",
    "\n",
    "# Combine the positive and negative pairs and labels\n",
    "pairs = pos_pairs + neg_pairs\n",
    "labels = pos_labels + neg_labels\n",
    "\n",
    "# Shuffle and split the dataset into training and validation sets\n",
    "pairs_train, pairs_val, labels_train, labels_val = train_test_split(pairs, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Define the input shape for the network\n",
    "input_shape = (num_features,)\n",
    "\n",
    "# Define the input layers for the Siamese network\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Define the base network for the Siamese network\n",
    "base_network = Sequential()\n",
    "base_network.add(Dense(128, activation='relu', input_shape=input_shape))\n",
    "base_network.add(Dense(128, activation='relu'))\n",
    "base_network.add(Dense(128, activation='relu'))\n",
    "base_network.add(Dense(128, activation='relu'))\n",
    "base_network.add(Dense(128, activation='relu'))\n",
    "base_network.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Define the output layers for the Siamese network\n",
    "encoded1 = base_network(input1)\n",
    "encoded2 = base_network(input2)\n",
    "merged_vector = concatenate([encoded1, encoded2], axis=-1)\n",
    "distance = Lambda(lambda x: K.abs(x[0] - x[1]))([encoded1, encoded2])\n",
    "output = Dense(1, activation='sigmoid')(distance)\n",
    "\n",
    "# Define the model for the Siamese network\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Define the contrastive loss function\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean((1-y_true) * K.square(y_pred) + y_true * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer)\n",
    "\n",
    "# Train the model on a dataset of pairs of poses that are either similar or dissimilar\n",
    "model.fit([pos1, pos2], labels, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: LSTM Network: The next step is to use an LSTM network to align the poses in a sequence.\n",
    "\n",
    "This code trains an LSTM neural network to classify the action of a person in a sequence of poses extracted from the Human3.6M dataset. The dataset contains motion capture data of people performing various actions, such as walking, running, etc.\n",
    "\n",
    "The code uses the H36MDataset class to load the dataset, which is stored as a collection of files in a directory hierarchy. The get_poses() method of the dataset class returns a list of PoseSequence objects, which represent sequences of poses for a single person performing a single action.\n",
    "\n",
    "The LSTM network is defined using the Keras library, with a single LSTM layer and a dense output layer. The input shape of the network is determined by the shape of a single pose in the dataset. The network is trained using binary cross-entropy loss and the Adam optimizer. During training, the code shuffles the list of pose sequences and divides them into batches. For each batch, it extracts the poses and labels from the PoseSequence objects and trains the network using the train_on_batch() method of the Keras model. After each epoch of training, the code prints the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from dataset import H36MDataset\n",
    "\n",
    "# Load the data\n",
    "dataset = H36MDataset(data_path='/path/to/h36m/dataset', subjects=['S1', 'S5'])\n",
    "\n",
    "# Get the poses\n",
    "poses = dataset.get_poses()\n",
    "\n",
    "# Define the model\n",
    "input_shape = poses[0].pose.shape\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(None, input_shape[1]), return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Shuffle the poses\n",
    "    np.random.shuffle(poses)\n",
    "    \n",
    "    # Split the poses into batches\n",
    "    num_batches = len(poses) // batch_size\n",
    "    for batch_num in range(num_batches):\n",
    "        batch_poses = poses[batch_num*batch_size:(batch_num+1)*batch_size]\n",
    "        x = np.array([pose.pose for pose in batch_poses])\n",
    "        y = np.array([1 if pose.action == 'walking' else 0 for pose in batch_poses])\n",
    "        model.train_on_batch(x, y)\n",
    "    \n",
    "    # Print the training loss\n",
    "    loss = model.evaluate(x, y, verbose=0)\n",
    "    print('Epoch {}/{} - loss: {:.4f}'.format(epoch+1, num_epochs, loss))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Hybrid Method: Once the Siamese network and LSTM network are trained, they can be combined to align and compare sequences of poses that are out of sync. The hybrid method works as follows:\n",
    "\n",
    "a. First, we input the two sequences of poses that need to be compared into the LSTM network to align them in time. The LSTM network outputs two sequences of aligned poses, one for each sequence.\n",
    "\n",
    "b. Next, we use the Siamese network to compare the similarity between the aligned poses in the two sequences. For each pair of aligned poses, we input them into the Siamese network to obtain a similarity score.\n",
    "\n",
    "c. Finally, we use the similarity scores obtained from the Siamese network to compare the two sequences of poses. We can compute the similarity between the two sequences by taking the average similarity score between corresponding pairs of aligned poses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Lambda, concatenate\n",
    "import numpy as np\n",
    "\n",
    "# Define the input shape for the network\n",
    "input_shape = (num_timesteps, num_features)\n",
    "\n",
    "# Define the input layers for the Siamese network\n",
    "input1 = Input(shape=input_shape)\n",
    "input2 = Input(shape=input_shape)\n",
    "\n",
    "# Define the LSTM network for sequence alignment\n",
    "lstm1 = LSTM(num_units)(input1)\n",
    "lstm2 = LSTM(num_units)(input2)\n",
    "\n",
    "# Define the Siamese network for pose comparison\n",
    "siamese = Sequential()\n",
    "siamese.add(Dense(num_units, activation='relu', input_shape=input_shape))\n",
    "siamese.add(Dense(num_units, activation='relu'))\n",
    "siamese.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compute the similarity score between pairs of aligned poses\n",
    "aligned1 = Lambda(lambda x: x[:, -1, :])(lstm1)\n",
    "aligned2 = Lambda(lambda x: x[:, -1, :])(lstm2)\n",
    "similarity = siamese([aligned1, aligned2])\n",
    "\n",
    "# Define the output layer for the network\n",
    "output = Dense(1, activation='sigmoid')(similarity)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[input1, input2], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model on a dataset of aligned pose sequences\n",
    "model.fit([aligned_poses1, aligned_poses2], labels, epochs=num_epochs, batch_size=batch_size)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code assumes that the LSTM model and siamese model have already been defined and trained in steps 1 and 2, respectively. The code also assumes that the input data is in the form of two sequences of poses, X1 and X2, with shape (num_poses, num_joints, joint_dim)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Align poses using LSTM\n",
    "# Assume X1 and X2 are the two input sequences of poses, each with shape (num_poses, num_joints, joint_dim)\n",
    "\n",
    "# Reshape input data to have time step as the first dimension\n",
    "X1 = X1.transpose((0, 2, 1))\n",
    "X2 = X2.transpose((0, 2, 1))\n",
    "\n",
    "# Create LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(64, input_shape=(None, X1.shape[2]), return_sequences=True))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(TimeDistributed(Dense(X1.shape[2])))\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Train LSTM model on input sequences\n",
    "lstm_model.fit(X1, X2, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "# Obtain aligned pose sequences\n",
    "aligned_X1 = lstm_model.predict(X1)\n",
    "aligned_X2 = lstm_model.predict(X2)\n",
    "\n",
    "\n",
    "# Step 2: Compute similarity scores using siamese network\n",
    "# Assume siamese_model is a pre-trained siamese network\n",
    "\n",
    "# Flatten the aligned pose sequences\n",
    "aligned_X1_flat = aligned_X1.reshape(aligned_X1.shape[0], -1)\n",
    "aligned_X2_flat = aligned_X2.reshape(aligned_X2.shape[0], -1)\n",
    "\n",
    "# Compute similarity scores using siamese network\n",
    "similarity_scores = []\n",
    "for i in range(aligned_X1_flat.shape[0]):\n",
    "    similarity_scores.append(siamese_model.predict([aligned_X1_flat[i], aligned_X2_flat[i]])[0][0])\n",
    "\n",
    "\n",
    "# Step 3: Compare sequences using similarity scores\n",
    "# Compute average similarity score between corresponding pairs of aligned poses\n",
    "average_similarity = np.mean(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8 (default, Apr 13 2021, 12:59:45) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdc2d5445f8831e6e510845367e868ab2e614605f18adbf0716630b2b6b00898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
